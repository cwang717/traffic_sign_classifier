{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Classification with Keras\n",
    "\n",
    "Keras exists to make coding deep neural networks simpler. To demonstrate just how easy it is, you’re going to use Keras to build a convolutional neural network in a few dozen lines of code.\n",
    "\n",
    "You’ll be connecting the concepts from the previous lessons to the methods that Keras provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The network you'll build with Keras is similar to the example that you can find in Keras’s GitHub repository that builds out a [convolutional neural network for MNIST](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py). \n",
    "\n",
    "However, instead of using the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, you're going to use the [German Traffic Sign Recognition Benchmark](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) dataset that you've used previously.\n",
    "\n",
    "You can download pickle files with sanitized traffic sign data here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Here are the steps you'll take to build the network:\n",
    "\n",
    "1. First load the data.\n",
    "2. Build a feedforward neural network to classify traffic signs.\n",
    "3. Build a convolutional neural network to classify traffic signs.\n",
    "\n",
    "Keep an eye on the network’s accuracy over time. Once the accuracy reaches the 98% range, you can be confident that you’ve built and trained an effective model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Start by importing the data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement data normalization code here.\n",
    "import pickle\n",
    "\n",
    "with open('../data/train.p', mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "X_train = train['features']\n",
    "y_train = train['labels']\n",
    "\n",
    "# STOP: Do not change the tests below. Your implementation should pass these tests. \n",
    "assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_train.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data\n",
    "\n",
    "Now that you've loaded the training data, normalize the input so that it has a mean of zero and a range between -0.5 and 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement data normalization code here.\n",
    "import numpy as np\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "X_train -= 0.5\n",
    "\n",
    "# STOP: Do not change the tests below. Your implementation should pass these tests. \n",
    "assert(round(np.mean(X_train)) == 0), \"The mean of the input data is: %f\" % np.mean(X_train)\n",
    "assert(np.min(X_train) == -0.5 and np.max(X_train) == 0.5), \"The range of the input data is: %.1f to %.1f\" % (np.min(X_train), np.max(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Two-Layer Feedfoward Network\n",
    "\n",
    "The code you've written so far is for data processing, not specific to Keras. Here you're going to build Keras-specific code.\n",
    "\n",
    "Build a two-layer feedforward neural network, with 128 neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement data normalization code here.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(32*32*3,), activation='relu', name=\"hidden1\"))\n",
    "model.add(Dense(43, activation='softmax', name=\"output\"))\n",
    "\n",
    "# STOP: Do not change the tests below. Your implementation should pass these tests.\n",
    "assert(model.get_layer(name=\"hidden1\").input_shape == (None, 32*32*3)), \"The input shape is: %s\" % model.get_layer(name=\"hidden1\").input_shape\n",
    "assert(model.get_layer(name=\"output\").output_shape == (None, 43)), \"The output shape is: %s\" % model.get_layer(name=\"output\").output_shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "Compile and train the network for two epochs. Use the `adam` optimizer, with a `categorical_crossentropy` loss.\n",
    "\n",
    "Hint 1: In order to use categorical cross entropy, you will need to one-hot encode the labels.\n",
    "\n",
    "Hint 2: In order to pass the input images to the fully-connected hidden layer, you will need to reshape the input.\n",
    "\n",
    "Hint 3: Keras's `.fit()` method returns a `History.history` object that the tests use. Save that to a variable named `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1088/1088 [==============================] - 2s 2ms/step - loss: 1.4171 - accuracy: 0.6198\n",
      "Epoch 2/2\n",
      "1088/1088 [==============================] - 2s 2ms/step - loss: 0.6263 - accuracy: 0.8257\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 43)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n",
    "history = model.fit(X_train, Y_train, epochs=2)\n",
    "\n",
    "# STOP: Do not change the tests below. Your implementation should pass these tests.\n",
    "assert(history.history['accuracy'][0] > 0.5), \"The training accuracy was: %.3f\" % history.history['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the Network\n",
    "Split the training data into a training and validation set.\n",
    "\n",
    "Measure the validation accuracy of the network after two training epochs.\n",
    "\n",
    "Hint: Use `train_test_split()` method from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "459/459 [==============================] - 1s 3ms/step - loss: 0.3920 - accuracy: 0.8894 - val_loss: 0.2909 - val_accuracy: 0.9254\n",
      "Epoch 2/2\n",
      "459/459 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.9040 - val_loss: 0.3291 - val_accuracy: 0.9056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=0)\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=2, validation_data=(X_val, Y_val)) \n",
    "\n",
    "# STOP: Do not change the tests below. Your implementation should pass these tests.\n",
    "assert(round(X_train.shape[0] / float(X_val.shape[0])) == 3), \"The training set is %.3f times larger than the validation set.\" % X_train.shape[0] / float(X_val.shape[0])\n",
    "assert(history.history['val_accuracy'][0] > 0.6), \"The validation accuracy is: %.3f\" % history.history['val_accuracy'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Accuracy**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations\n",
    "You've built a feedforward neural network in Keras!\n",
    "\n",
    "Don't stop here! Next, you'll add a convolutional layer to drive.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions\n",
    "Build a new network, similar to your existing network. But before the hidden layer, add a 3x3 convolutional layer with 32 filters and valid padding.\n",
    "\n",
    "Then compile and train the network.\n",
    "\n",
    "Hint 1: Now that the first layer of the network is a convolutional layer, you no longer need to reshape the input images before passing them to the network. You might need to reload your training data to recover the original shape.\n",
    "\n",
    "Hint 2: Add a `Flatten()` layer between the convolutional layer and the fully-connected hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "816/816 [==============================] - 4s 4ms/step - loss: 1.3283 - accuracy: 0.6452 - val_loss: 0.5162 - val_accuracy: 0.8686\n",
      "Epoch 2/2\n",
      "816/816 [==============================] - 3s 4ms/step - loss: 0.3716 - accuracy: 0.9009 - val_loss: 0.3004 - val_accuracy: 0.9247\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Convolution2D, Flatten\n",
    "\n",
    "X_train = train['features']\n",
    "y_train = train['labels']\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "X_train -= 0.5\n",
    "Y_train = np_utils.to_categorical(y_train, 43)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, padding='valid', input_shape=X_train.shape[1:], activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(43, activation='softmax')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=2, validation_data=(X_val, Y_val))\n",
    "\n",
    "# STOP: Do not change the tests below. Your implementation should pass these tests.\n",
    "assert(history.history['val_accuracy'][0] > 0.8), \"The validation accuracy is: %.3f\" % history.history['val_accuracy'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Accuracy**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "Re-construct your network and add a 2x2 pooling layer immediately following your convolutional layer.\n",
    "\n",
    "Then compile and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "816/816 [==============================] - 2s 3ms/step - loss: 1.9762 - accuracy: 0.4461 - val_loss: 1.1183 - val_accuracy: 0.6875\n",
      "Epoch 2/2\n",
      "816/816 [==============================] - 2s 3ms/step - loss: 0.8991 - accuracy: 0.7297 - val_loss: 0.7461 - val_accuracy: 0.7733\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, padding='valid', input_shape=X_train.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(43, activation='softmax')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=2, validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Re-construct your network and add dropout after the pooling layer. Set the dropout rate to 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "816/816 [==============================] - 2s 3ms/step - loss: 2.2524 - accuracy: 0.3616 - val_loss: 1.4132 - val_accuracy: 0.5959\n",
      "Epoch 2/2\n",
      "816/816 [==============================] - 2s 3ms/step - loss: 1.3463 - accuracy: 0.5843 - val_loss: 0.9839 - val_accuracy: 0.7064\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, padding='valid', input_shape=X_train.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(43, activation='softmax')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=2, validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "Congratulations! You've built a neural network with convolutions, pooling, dropout, and fully-connected layers, all in just a few lines of code.\n",
    "\n",
    "Have fun with the model and see how well you can do! Add more layers, or regularization, or different padding, or batches, or more training epochs.\n",
    "\n",
    "What is the best validation accuracy you can achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Validation Accuracy:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Once you've picked out your best model, it's time to test it.\n",
    "\n",
    "Load up the test data and use the `evaluate()` method to see how well it does.\n",
    "\n",
    "Hint: After you load your test data, don't forget to normalize the input and one-hot encode the output, so it matches the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 0s 1ms/step - loss: 1.3353 - accuracy: 0.5945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3353384733200073, 0.5944576263427734]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/test.p', mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_test = test['features']\n",
    "y_test = test['labels']\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "X_test -= 0.5\n",
    "Y_test = np_utils.to_categorical(y_test, 43)\n",
    "\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Accuracy:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Keras is a great tool to use if you want to quickly build a neural network and evaluate performance."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
